{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /oscar/home/dgada/.venv/lib/python3.9/site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium) (2.0.2)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: zipp>=3.20 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.21.0)\n",
      "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, cloudpickle, gymnasium\n",
      "Successfully installed cloudpickle-3.1.1 farama-notifications-0.0.4 gymnasium-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[toy-text] in /oscar/home/dgada/.venv/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium[toy-text]) (2.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium[toy-text]) (3.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium[toy-text]) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium[toy-text]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from gymnasium[toy-text]) (0.0.4)\n",
      "Collecting pygame>=2.1.3 (from gymnasium[toy-text])\n",
      "  Downloading pygame-2.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /oscar/home/dgada/.venv/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium[toy-text]) (3.21.0)\n",
      "Downloading pygame-2.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[toy-text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/dgada/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 done\n",
      "Episode 40 done\n",
      "Episode 60 done\n",
      "Episode 80 done\n",
      "Episode 100 done\n",
      "Episode 120 done\n",
      "Episode 140 done\n",
      "Episode 160 done\n",
      "Episode 180 done\n",
      "Episode 200 done\n",
      "Episode 220 done\n",
      "Episode 240 done\n",
      "Episode 260 done\n",
      "Episode 280 done\n",
      "Episode 300 done\n",
      "Episode 320 done\n",
      "Episode 340 done\n",
      "Episode 360 done\n",
      "Episode 380 done\n",
      "Episode 400 done\n",
      "Episode 420 done\n",
      "Episode 440 done\n",
      "Episode 460 done\n",
      "Episode 480 done\n",
      "Episode 500 done\n",
      "Episode 500/5000, Avg Reward: 0.00, Epsilon: 0.08\n",
      "Episode 520 done\n",
      "Episode 540 done\n",
      "Episode 560 done\n",
      "Episode 580 done\n",
      "Episode 600 done\n",
      "Episode 620 done\n",
      "Episode 640 done\n",
      "Episode 660 done\n",
      "Episode 680 done\n",
      "Episode 700 done\n",
      "Episode 720 done\n",
      "Episode 740 done\n",
      "Episode 760 done\n",
      "Episode 780 done\n",
      "Episode 800 done\n",
      "Episode 820 done\n",
      "Episode 840 done\n",
      "Episode 860 done\n",
      "Episode 880 done\n",
      "Episode 900 done\n",
      "Episode 920 done\n",
      "Episode 940 done\n",
      "Episode 960 done\n",
      "Episode 980 done\n",
      "Episode 1000 done\n",
      "Episode 1000/5000, Avg Reward: 0.01, Epsilon: 0.01\n",
      "Episode 1020 done\n",
      "Episode 1040 done\n",
      "Episode 1060 done\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Login\n",
    "login_token = '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'\n",
    "login(login_token)\n",
    "\n",
    "# Load Model\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Environment\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"ansi\")\n",
    "num_eps = 5000\n",
    "\n",
    "# Memory History Class\n",
    "class TransitionHistory:\n",
    "    def __init__(self, size=5):\n",
    "        self.history = []\n",
    "        self.size = size\n",
    "\n",
    "    def add(self, state, action, next_state):\n",
    "        self.history.append((state, action, next_state))\n",
    "        if len(self.history) > self.size:\n",
    "            self.history.pop(0)\n",
    "\n",
    "    def get(self):\n",
    "        return self.history.copy()\n",
    "\n",
    "# Summary generator\n",
    "def summarize_experience(episode_history):\n",
    "    action_map = ['left', 'down', 'right', 'up']\n",
    "    summary_prompt = (\n",
    "        f\"### Instruction:\\n\"\n",
    "        f\"Summarize this agent's experience in Frozen Lake. What mistakes or good moves did it make?\\n\"\n",
    "        f\"Transitions:\\n\" +\n",
    "        \"\\n\".join([f\"{s} -> {ns} via {action_map[a]}\" for s, a, ns in episode_history]) +\n",
    "        \"\\n### Response:\\n\"\n",
    "    )\n",
    "    inputs = tokenizer(summary_prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Main reward function\n",
    "def get_language_reward(state, action, next_state, grid_map, memory=None, summary_text=None):\n",
    "    action_map = ['left', 'down', 'right', 'up']\n",
    "    action_name = action_map[action]\n",
    "\n",
    "    history_str = \"\"\n",
    "    if memory:\n",
    "        history_str = \"Here are recent steps:\\n\" + \"\\n\".join(\n",
    "            [f\"{h[0]} -> {h[2]} via {action_map[h[1]]}\" for h in memory]\n",
    "        ) + \"\\n\"\n",
    "\n",
    "    summary_str = \"\"\n",
    "    if summary_text:\n",
    "        summary_str = f\"\\nAgent memory: {summary_text}\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"### Instruction:\\n\"\n",
    "        f\"You are evaluating a move made by an agent in Frozen Lake (4x4 grid, goal at state 15).\\n\"\n",
    "        f\"The layout is: {grid_map}.\\n\"\n",
    "        f\"{history_str}\"\n",
    "        f\"The current move: {state} to {next_state} via {action_name}.\\n\"\n",
    "        f\"{summary_str}\"\n",
    "        f\"Rate this move from 0 (bad) to 1 (excellent).\\n\"\n",
    "        f\"### Response:\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        reward_str = response.split(\"### Response:\")[-1].strip()\n",
    "        reward_val = float(reward_str.split()[0])\n",
    "        reward_val = max(0.0, min(1.0, reward_val))\n",
    "    except:\n",
    "        reward_val = 0.0\n",
    "\n",
    "    return reward_val\n",
    "\n",
    "# Q-learning loop\n",
    "def q_learning_llm(env, num_episodes=5000, memory_type=\"none\", alpha=0.5, gamma=0.95,\n",
    "                   initial_epsilon=1.0, min_epsilon=0.01, epsilon_decay=0.995):\n",
    "\n",
    "    q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "    epsilon = initial_epsilon\n",
    "    rewards_per_episode = []\n",
    "    env.reset()\n",
    "    grid_map = env.render()\n",
    "\n",
    "    model_root = \"models\"\n",
    "    os.makedirs(model_root, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(model_root, timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    save_every = 500\n",
    "    memory = TransitionHistory(size=3)\n",
    "    summary_memory = \"\"\n",
    "    full_episode_history = []\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        memory.history.clear()\n",
    "        full_episode_history.clear()\n",
    "\n",
    "        while not done:\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            next_state, _, done, truncated, info = env.step(action)\n",
    "\n",
    "            # Update memory\n",
    "            memory.add(state, action, next_state)\n",
    "            full_episode_history.append((state, action, next_state))\n",
    "\n",
    "            if memory_type == \"short\":\n",
    "                reward = get_language_reward(state, action, next_state, grid_map, memory=memory.get())\n",
    "            elif memory_type == \"summary\":\n",
    "                reward = get_language_reward(state, action, next_state, grid_map, summary_text=summary_memory)\n",
    "            else:\n",
    "                reward = get_language_reward(state, action, next_state, grid_map)\n",
    "\n",
    "            q_table[state, action] += alpha * (\n",
    "                reward + gamma * np.max(q_table[next_state]) - q_table[state, action]\n",
    "            )\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "        total_reward /= steps\n",
    "        rewards_per_episode.append(total_reward)\n",
    "\n",
    "        # Update summary memory every 100 episodes\n",
    "        if memory_type == \"summary\" and (i + 1) % 100 == 0:\n",
    "            summary_memory = summarize_experience(full_episode_history)\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"Episode {i+1} done\")\n",
    "\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "        if (i + 1) % save_every == 0:\n",
    "            avg_reward = np.mean(rewards_per_episode[-save_every:])\n",
    "            print(f\"Episode {i+1}/{num_episodes}, Avg Reward: {avg_reward:.2f}, Epsilon: {epsilon:.2f}\")\n",
    "            save_path = os.path.join(run_dir, f\"q_table_ep{i+1}.pkl\")\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                pickle.dump(q_table, f)\n",
    "\n",
    "    return q_table, rewards_per_episode\n",
    "\n",
    "# Run with memory\n",
    "memory_type = \"short\"  # Options: \"none\", \"short\", \"summary\"\n",
    "q_table, rewards = q_learning_llm(env, num_episodes=num_eps, memory_type=memory_type)\n",
    "\n",
    "# Plot rewards\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(rewards)\n",
    "plt.title(f'Rewards per Episode ({memory_type} memory)')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()\n",
    "\n",
    "# Q-Table\n",
    "def print_q_table(q_table, env):\n",
    "    actions = ['Left', 'Down', 'Right', 'Up']\n",
    "    df = pd.DataFrame(q_table, columns=actions)\n",
    "    df.index.name = 'State'\n",
    "    print(\"\\n===== Q-Table =====\")\n",
    "    print(df.round(2))\n",
    "    print(\"===================\\n\")\n",
    "\n",
    "print_q_table(q_table, env)\n",
    "\n",
    "# Visualization (commented for OOD)\n",
    "# env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")\n",
    "# visualize_agent(env, q_table, episodes=1)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
