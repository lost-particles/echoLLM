Language Models as Reward Functions for Reinforcement Learning : 

Abstract :

In this Project, we propose a framework in which large language models (LLMs) generate reward signals by evaluating agent transi-
tions against human-readable task descriptions. We instantiate this approach in two benchmark environments—Frozen Lake and Black-
jack—within a Q-learning paradigm, comparing LLM-derived rewards in no-memory, long-term, short-term, and summary-memory modes against 
traditional numeric rewards trained over 500 episodes for Blackjack and 400 episodes for Frozen Lake. Our results highlight
the potential of language-driven rewards to provide a more flexible and intuitive mechanism for training RL agents toward generalizable
behaviors, advancing the path toward AGI.
